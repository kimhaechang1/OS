## 메모리

### 스와핑

현재 사용되지 않는 프로세스들을 보조기억장치의 일부 영역으로 쫓아내고

그렇게 생긴 빈 공간에 새 프로세스를 적재

![alt text](./images/image-20.png)

스와핑은 어떨 때 사용할까 ?

- 프로세스들이 요구하는 메모리 공간 크기 > 실제 메모리 크기

### 메모리 할당

프로세스는 메모리의 빈 공간에 할당되어야 한다.

그 방법으로 `최초 적합`, `최적 적합`, `최악 적합` 으로 세 가지 방식이 있다.

### 연속 메모리 할당: 프로세스에 연속적인 메모리 공간을 할당

**최초 적합(`First-Fit`)**

운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재 가능한 공간을 발견하면 프로세스를 배치함

- 검색 시간 최소화, 빠른 할당

**최적 적합(`Best-Fit`)**

운영체제가 빈 공간을 모두 검색해본 뒤, 적재 가능한 가장 작은 공간에 할당

**최악 적합(`Worst-Fit`)**

운영체제가 빈 공간을 모두 검색해본 뒤, 적재 가능한 가장 큰 공간에 할당

![alt text](./images/image-19.png)

사실, 언뜻 보기엔 좋아보여도 이렇게 연속적으로 프로세스를 메모리에 할당하는 방식은 효율적이지 않음

그 이유는 `외부 단편화(external fragmentation)`이라는 문제가 발생하기 때문

### 외부 단편화(`External Fragment`)

```
Case

사용자 영역이 200MB 일 때

크기가 50MB인 프로세스 A, 30MB인 프로세스 B, 100MB인 프로세스 C, 20MB인 프로세스 D를 차례대로 적재해야 한다면?
```
위 상황에서 프로세스 B, D가 실행이 종료되어 메모리가 반환되었다면?

![alt text](./images/image-21.png)

빈 공간에 총 합은 50MB, 하지만 프로세스 50MB짜리를 할당 가능한가요? No

이러한 문제를 `외부 단편화` 라고 부른다.

외부 단편화 해결방법

- `메모리 압축(Compaction)`: 여기저기 흩어져 있는 빈 공간들을 하나로 모으는 방식으로, 재배치 시켜 흩어져 있는 작은 빈 공간들을 하나의 큰 빈 공간으로 만드는 방법
    - ![alt text](./images/image-22.png)

하지만 위의 방법으로는 `재배치`에 따른 오버헤드로 인해 해당 프로세스가 원래 수행해야 할 일을 일시 중단해야 하는 문제가 발생한다.

따라서 현대 메모리관리법인 `페이징`이 등장하게 된다.

## 페이징을 통한 가상 메모리 관리

`연속적인 메모리 할당`은 `외부 단편화` 문제를 야기시키고, 이를 메모리 압축(`Compaction`)으로 해결하려니 `재배치`에 대한 오버헤드가 너무 크다.

`따라서 페이징을 통한 가상 메모리 관리`를 통해 `외부 단편화` 문제를 해결한다.

- 가상 메모리: 실행되고자 하는 프로세스가 필요하는 메모리의 양이 남은 메모리보다 크더라도 프로세스의 일부 정보만을 메모리에 적재하여, 남은 메모리보다 더 많은 프로세스를 실행 가능케 하는 기술

    - 이를 구현한 것이 `페이징`, `세그멘테이션`이 있다.


이전까지의 문제는 `프로세스가 필요한 양 만큼만 연속적으로 메모리를 할당` 하였다.

그로 인해 `외부 단편화`가 발생되었는데, `페이징`은 `모든 프로세스를 일정 크기로 자르고, 이를 불연속적으로 할당 하는 것` 이다.

`페이징(Paging)`
- 프로세스의 `논리 주소 공간을 페이지`라는 일정 단위로 자르고

- 메모리의 `물리 주소 공간을 프레임`이라는 페이지와 동일한 일정한 단위로 자른 뒤, `페이지를 프레임에 할당하는 가상 메모리 관리 기법`

- ![alt text](./images/image-23.png)

페이징에서도 스와핑은 충분히 가능하다.

- 작동 방식은 페이징을 안쓰더라도 동일하다. `페이지 단위`가 될 뿐이다.

    - 즉, 프로세스는 메모리공간 내 일부 페이지에 대하여 보조기억장치의 스왑공간에 적재된 체로 실행 되기도 한다.
    - ![alt text](./images/image-24.png)

    - 따라서 프로세스가 필요한 메모리가 남은 메모리보다 크더라도 실행이 가능하게 된다.

그런데 페이징에서 `논리 주소 공간`은 `페이지 단위`로 자르고, 이를 또 일정한 단위로 잘린 물리 메모리 내에 `프레임`에 `불 연속적`으로 할당한다고 했다.

CPU가 해당 프로세스를 실행하려고 봤더니 `연속 메모리 할당때`에는 프로세스마다 `시작주소 + 변위`로 찾을 수 있겠지만 

`불 연속적`으로 논리 메모리 구조인 `페이지`를 `물리메모리 프레임`에 할당하는 `페이징 기법`에서는 하나의 프로세스를 이루는 `물리 메모리 파편`을 찾기가 힘들다.

그래서 `페이지 테이블`이 있다.

현재 어떤 프로세스의 어떤 페이지가 어떤 프레임과 연결되어 있는지 찾을 수 있는 테이블

- 즉, 실제 메모리는 프레임과 페이지로 연결관계로 되어있어 하나의 프로세스에 대하여 불연속적일지라도
- CPU 입장에서는 적어도 연속적으로 보이도록 배치하는 방법

- 이러한 페이지 테이블은 프로세스 마다 존재하게 된다.
    - 프로세스 마다 이루는 물리 메모리공간이 프레임단위로 불연속적이기 때문에 프로세스 마다 있어야 한다.

    - ![alt text](./images/image-25.png)

    - 따라서 `CPU 입장`에서는 `페이지 테이블`을 보고 `순차적`으로 페이지들을 실행하면 그만이다.

페이징은 `내부 단편화`가 있을 수 있다.

```
페이지의 크기가 10KB, 프로세스의 크기가 108KB 일 때를 생각해보면

논리 메모리 공간에서는 10KB 크기로 짤릴 것이고 프로세스에게 필요한 만큼을 할당해주기 위해서 11개의 페이지를 할당 할 것이다.

그런데 110KB 를 할당하면..
```
![alt text](./images/image-26.png)

2KB: 내부 단편화가 발생!

### PTBR (`Page Table Base Register`)

CPU가 프로세스를 실행하기 앞서, 프로세스의 `페이지 테이블`을 살펴 볼 것인데

이 `페이지 테이블의 위치가 어딨는지 알아야 할 것`이다. 이것을 `기억`해 두는 특별한 레지스터가 바로 `PTBR`이다.

근데 `페이지 테이블`이 `메모리위에 있게 되면` 메모리 접근시간이 `2배`가 된다.

- 그 이유로, CPU가 해당 프로세스를 실행하면서 프로세스가 점유하고 있는 메모리에 접근해야 할 때, 페이지 테이블을 거쳐야 한다.

    - 이 때 페이지 테이블에 접근하기 위해 `PTBR`을 통해 `메모리 위에 있는 페이지 테이블`에 접근하고,

    - 얻은 페이지 테이블에서 `현재 가진 페이지 정보에 따른 물리 메모리에 접근하기 위해 한번 더 메모리에 접근`하게 된다.

그래서 `TLB`를 통해 메모리 접근횟수를 줄일 수 있다.

`TLB`: CPU 곁에 있으며, 페이지 테이블을 위한 캐시 메모리

- 페이지 테이블의 일부를 가져와서 저장

    - 따라서 자주사용되는 페이지 테이블 일부가 저장되어 있으므로 곧바로 논리 메모리내에 페이지에 접근이 가능케 된다.


### 페이지 테이블의 심화내용

페이지 테이블은 프로세스 마다 있으며, 페이징 기법에 의한 불연속적인 프레임들을 하나의 연속적인 페이지로 관리할 수 있게 된다.

그리고 이러한 페이지 테이블 내에는 결국 페이지와 연결된 프레임이 매핑테이블로 이루어져 있는데,

여기서 매핑 테이블을 이루는 데이터 하나하나를 페이지 테이블 엔트리라고 부른다.

중요한 점은 만약 CPU가 논리적인 주소인 몇번 페이지에 일정 변위만큼 떨어져있는 메모리 값을 읽어오려고 한다면

페이지 테이블 내에 이어진 프레임을 찾으면 되고, 변위를 동일하게 해당 프레임번호에서 더하면 읽을 수 있다.

이게 가능한 이유는 프레임의 크기단위와 페이지의 크기단위가 동일하기 때문이다.

이러한 페이지 테이블은 단순히 페이지번호 - 프레임 번호 로만 이루어져 있지 않고, 사실 몇가지 추가 비트들이 있다.

이는 OS마다 조금씩 편차가 있다.

### 유효 비트

유효 비트는 현재 페이지테이블 내에 존재하는 해당 페이지가 메모리 위에 있는지 여부를 나타내는 비트이다.

만약 없다면 Page Fault 인터럽트를 발생시켜서 해당 페이지의 내용을 스왑된 보조기억장치로부터 읽어들여 메모리위에 올리고 유효비트를 켠다.

### 보호 비트

이는 페이지의 속성을 지키기위한 비트로서, 예를들어 읽기전용일 경우, 쓰기 전용일 경우 이런 경우에 따라 비트를 켜고 끈다.

### 참조 비트

CPU 가 한번이라도 참조한 적 이 있는지 여부를 나타내는 비트이다.

### 수정 비트

수정 비트는 이 페이지에 들어있는 값이 수정 된 적 있는지 여부를 나타내며, 이는 페이지단위로 스왑될 때 중요하다.

왜냐하면 수정비트가 켜져있는 경우에는, 보조기억장치에 있는 페이지의 값도 수정해야 하기 때문이다.

## CopyOnWrite 와 계층적 페이징

먼저 fork() 라는 시스템 콜을 통해 자신과 동일한 프로세스를 만들어 낼 수있다.

하지만 기본적으로는 프로세스들은 메모리를 공유하지 않기 때문에 계속해서 fork()를 하게되면 금방 메모리를 꽉채우게 된다.

여기서 CopyOnWrite를 하게 되면, 프로세스에서 fork()가 발생하더라도 메모리를 새롭게 할당하지 않는다.

기존 부모 프로세스와 동일한 프레임을 갖고 있다가, 부모든 자식이든 어디 페이지에서 수정이 발생하면 그 페이지에 대한 내용을 새로운 프레임에 복사하고 수정하게 된다.

이것으로 메모리를 절약할 수 있다.

또한 계층적 페이징으로도 메모리를 절약 할 수 있다.

이는 페이지로 나눠진 페이지들을 또 페이지기법으로 나누는 것을 의미한다.

페이지들을 묶어서 하나의 단위로서 사용하는 것이 된다. 이 때 나누고있는 페이지를 아우터 페이지라고 부른다.

그렇게 되면 하나의 테이블 엔트리에서 페이지쪽이 기존에는 <페이지번호, 변위> 였다면 이제는 아우터 <페이지번호, 페이지 번호, 변위> 가 된다.

그래서 실제 메모리위에 페이지 테이블 엔트리의 크기는 더욱 작게 유지할 수 있게 된다.

## 페이지 교체 알고리즘

CPU가 특정 명령어를 읽기 위해서 페이지에 접근할 때, 해당 페이지가 메모리 위에 있는지 없는지 여부를 `유효비트`를 통해 확인할 것이고

유효비트가 꺼져있으면 `page fault` 인터럽트 발생 후 보조기억장치로부터 해당 페이지를 들고 오고 유효비트를 켤 것이다.

생각해보면 물리적인 메모리 단위인 `프레임`은 언제나 한정적이기 때문에, 페이지단위로 보조기억장치로 스와핑하면서 물리메모리보다 더큰 프로세스를 실행해야 한다.

그래서 새로운 페이지에 대한 요구가 발생 할때, 할당안된 프레임이 없다면 페이지가 할당된 프레임 들 중 어떤 기준을 통해 보조기억장치로 스와핑하고 해당 프레임에 새로운 페이지를 할당하는것이다.

```
여기서 CPU가 필요할 때 마다 페이지를 요구하는것을 "요구 페이징"이라고 한다.
```

그런데 위의 상황처럼 제한된 프레임을 넘어서는 새로운 페이지를 불러와야 할 때, 

이전 프레임들에 할당된 페이지들 중 어떤 페이지를 보조기억장치로 넣어버릴까를 다루는 것이 `페이지 교체 알고리즘` 이다.

페이지 교체 알고리즘의 주 목적은 바로 `page fault` 인터럽트의 발생 `최소화`를 목적으로 둔다.

왜냐하면 페이지 폴트 인터럽트 루틴에 의해 보조기억장치까지 읽으러 가야하기 때문이다.

이렇게 페이지 교체 시점을 계산하기 위해서, CPU에는 페이지번호 별 참조 수열을 갖고 있다.

그리고 이들 중 `연속되는 같은 페이지번호를 생략한 수열`을 `페이지 참조열(page reference string)` 이라고 한다.

```
어떤 프로세스를 실행하는데 모든 페이지가 물리적인 메모리위에 있을 필요는 없다.

왜냐하면 프로세스가 접근하는 메모리 주소는 가상 메모리 주소 영역대를 사용할 것이기 때문이다.

여기서 가상메모리로 되어있는 페이지는 실제 메모리가 붙어져 있지 않을 수 있다.

즉, RAM위에 없을수도있다.

나중에 해당 프로세스를 CPU를 점유하여 실행하면서, 명령어를 처리하기 위해 페이지에 접근 할 것이다.

그런데 프레임이 현재 할당되어있지 않다면 해당 페이지가 물리메모리위에 없다고 간주하고 페이지폴트를 발생시킨다.

여기서 빈 프레임이 없다고 판단되면 페이지교체 알고리즘이 실행되고, 교체대상인 페이지에 대하여 보조기억장치로 스와핑하고

해다아 프레임을 현재 요구하는 페이지번호에 할당한다.
```

예를들어

```
233553377
```
이라는 페이지 번호수열에서는 2번다음 3번을 두번연속 참조하고.. 이런것을 볼 수 있고

결국 이들 중 연속된 부분을 생략하면

```
23537
```
이것을 통해 `페이지 폴트가 언제 발생`하는지를 알 수 있다.

### FIFO 페이지 교체 알고리즘

제일 단순한 알고리즘으로, 가장 먼저 삽입된 페이지번호를 가장 오래된 페이지로 간주하고 교체 대상으로 잡는다.

예를들어 
```
2 3 1 5 3 5 2 3 4 2 3
```
페이지 참조열이 다음과 같고, 프레임 개수가 3개 라고 가정해보자.

여기서 2, 3, 1 에 대해 읽어들이는 페이지 폴트는 생략한다.

그러면 5를 읽어들일 때, 미리 프레임들에 할당된 각 페이지번호인 2 와 3과 1 중에 누가 빠져야 할까? 

FIFO에서는 가장 먼저 들어온것이 나가야 하므로 2가 5로 교체되고 2는 보조기억장치로 들어간다.

하지만 이러한 FIFO 알고리즘은 정말 단순하기 때문에, 

만약 프로세스 실행초기에 읽어들인 페이지라고 해서 곧바로 보조기억장치로 이동하게 된다.

### FIFO 세컨드찬스 알고리즘

위의 FIFO 알고리즘에서 보조변수로서 참조비트의 켜짐여부를 체크한다.

기본적인 교체 순서는 FIFO와 동일하나 동작시에,

`참조비트가 켜져`있다면, 한번이라도 CPU가 사용하였던 페이지라고 생각하고 프레임의 가장 뒤로 보내버리고 참조비트도 꺼버린다.

만약 `참조비트가 꺼져`있다면 곧바로 교체 대상으로 확인하고 교체한다.

### 최적 페이지교체 알고리즘

이상적인 알고리즘으로, 없어도 될 페이지를 교체하고, 오래동안 쓰일 페이지를 남기는 알고리즘

하지만 말그대로 이상에 가까운 알고리즘이기 때문에 "오래동안" 과 "없어도 될"의 정도를 잡아야 한다.

### LRU (Least Recently Used)

가장 오래동안 사용하지 않은 페이지를 교체하는 알고리즘으로서

페이지 참조열을 통해 가장 오래동안 언급되지 않은 페이지번호를 교체대상으로 잡는다.

## 스레싱과 프레임 할당

페이지 폴트가 너무많이 발생하는경우 CPU가 제할일을 못하는 상황이 생긴다.

이를 스레싱이라고 한다.

이러한 스레싱이 덜 일어나기 위해서는 어느정도 양의 프레임을 프로세스에 할당하는지에 걸려있다.

여기서 `정적 할당 방식` 과 `동적 할당 방식`으로 나뉜다.

- 정적 할당 방식

    - 균등 할당: 모든 프로세스들에게 균등한 개수의 프레임을 할당한다.
        - 이는 당연지기 낭비되는경우도 충분히 고려할 수 없다.

    - 크기기반 할당: 프로세스의 요구되는 메모리크기에 따라 프레임을 할당한다.
        - 프로세스 실행도중에 갑자기 프레임요구가 많아질 수 있다.

- 동적 할당 방식

    - 작업집합 기반 할당: 특정 시간간격 내에 사용되는 페이지번호의 개수를 관찰하고 이를 기반으로 프레임을 할당하는 방식

    - 페이지 빈도기반 할당: 너무많은 프레임을 할당하면 페이지폴트가 적게 발생하고, 너무 적은 프레임을 할당하면 페이지폴트가 자주 발생한다. 이에 따라 적절한 상한선과 하한선을 만들어서 그만큼만 프레임을 할당하는 방식




